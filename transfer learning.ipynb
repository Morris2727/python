{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as sf\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, Conv2D, GlobalAveragePooling2D, Activation,MaxPooling2D,MaxPool2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀入cifar10資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 116s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = datasets.cifar10.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "category= ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 檢視我們的測試資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 31.5, 31.5, -0.5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = np.random.randint(X_train.shape[0])\n",
    "X_sample = X_train[n]\n",
    "y_sample = Y_train[n].squeeze()\n",
    "\n",
    "plt.imshow(X_sample)\n",
    "plt.title(category[y_sample])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 標準化資料\n",
    "### 將資料轉成0到1之間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / X_train.max()\n",
    "X_test = X_test / X_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train, 10)\n",
    "Y_test = to_categorical(Y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看數據型態\n",
    "### 圖片為32X32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立分類cifar10的卷積神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_layers = [Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu', name='Conv_1'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(128, (3, 3), padding='same', activation='relu', name='Conv_2'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(512, (3, 3), padding='same', activation='relu', name='Conv_3'),\n",
    "              GlobalAveragePooling2D()]\n",
    "\n",
    "FC_layers = [Dense(units=128, activation='relu'),\n",
    "             Dense(units=10, activation='softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 16, 16, 128)       36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 8, 8, 512)         590336    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 695,178\n",
      "Trainable params: 695,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(CNN_layers + FC_layers)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 組裝神經網路及訓練模型\n",
    "### 設定訓練數值:batch_size = 300 ,epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 352s 7ms/sample - loss: 1.6019 - categorical_accuracy: 0.4053 - val_loss: 1.5592 - val_categorical_accuracy: 0.4232\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 348s 7ms/sample - loss: 1.5435 - categorical_accuracy: 0.4312 - val_loss: 1.5124 - val_categorical_accuracy: 0.4429\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 345s 7ms/sample - loss: 1.4918 - categorical_accuracy: 0.4527 - val_loss: 1.5432 - val_categorical_accuracy: 0.4295\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 359s 7ms/sample - loss: 1.4535 - categorical_accuracy: 0.4683 - val_loss: 1.4095 - val_categorical_accuracy: 0.4879\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 350s 7ms/sample - loss: 1.4114 - categorical_accuracy: 0.4873 - val_loss: 1.3660 - val_categorical_accuracy: 0.5041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b16cd2db00>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train, \n",
    "           batch_size=1000, \n",
    "           epochs=5,\n",
    "          validation_data=(X_test, Y_test)\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 156s 3ms/sample - loss: 1.3659 - categorical_accuracy: 0.5057\n",
      "10000/10000 [==============================] - 31s 3ms/sample - loss: 1.3660 - categorical_accuracy: 0.5041\n",
      "Train Accuracy: 50.56599974632263\n",
      "Test Accuracy: 50.41000247001648\n"
     ]
    }
   ],
   "source": [
    "score_train = model.evaluate(X_train, Y_train)\n",
    "score_test = model.evaluate(X_test, Y_test)\n",
    "print(f'Train Accuracy: {score_train[1]*100}')\n",
    "print(f'Test Accuracy: {score_test[1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('LeNet5_CIFAR10_HW.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 遷移學習 (Transfer Learning) 中的 Layer Transfer 的技巧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D \n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀入 Fasion mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = X_train_2.reshape(60000, 28, 28, 1)/255\n",
    "X_test_2 = X_test_2.reshape(10000, 28, 28, 1)/255\n",
    "# One-hot encoding\n",
    "y_train_2 = to_categorical(y_train_2, 10)\n",
    "y_test_2 = to_categorical(y_test_2, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立Model2模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重新設定fashion_mnist CNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_layers_mnist = [Conv2D(32, (3, 3), input_shape=(28, 28, 1), padding='same', activation='relu', name='Conv_1'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(128, (3, 3), padding='same', activation='relu', name='Conv_2'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(512, (3, 3), padding='same', activation='relu', name='Conv_3'),\n",
    "              GlobalAveragePooling2D()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 應用Transfer Learning : 使用model的FC_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 14, 14, 128)       36992     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 7, 7, 512)         590336    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 694,602\n",
      "Trainable params: 694,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential(CNN_layers+FC_layers)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 333s 6ms/sample - loss: 0.9862 - categorical_accuracy: 0.6670 - val_loss: 0.7732 - val_categorical_accuracy: 0.7340\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 330s 6ms/sample - loss: 0.7053 - categorical_accuracy: 0.7463 - val_loss: 0.6788 - val_categorical_accuracy: 0.7509\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 329s 5ms/sample - loss: 0.6511 - categorical_accuracy: 0.7608 - val_loss: 0.6333 - val_categorical_accuracy: 0.7649\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 331s 6ms/sample - loss: 0.6103 - categorical_accuracy: 0.7769 - val_loss: 0.5999 - val_categorical_accuracy: 0.7801\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 331s 6ms/sample - loss: 0.5756 - categorical_accuracy: 0.7896 - val_loss: 0.5639 - val_categorical_accuracy: 0.7988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1afe956d7b8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer=Adam(),metrics=['categorical_accuracy'])\n",
    "model2.fit(X_train_2, y_train_2, batch_size=1000, epochs=5,validation_data=(X_test_2, y_test_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 存下模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save_weights('transferlearning_HW_mnist.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 150s 3ms/sample - loss: 0.5458 - categorical_accuracy: 0.8031\n",
      "10000/10000 [==============================] - 25s 3ms/sample - loss: 0.5639 - categorical_accuracy: 0.7988\n",
      "Train Accuracy: 80.30999898910522\n",
      "Test Accuracy: 79.8799991607666\n"
     ]
    }
   ],
   "source": [
    "model2.load_weights('transferlearning_HW_mnist.h5')\n",
    "\n",
    "score_train = model2.evaluate(X_train_2, y_train_2)\n",
    "score_test = model2.evaluate(X_test_2, y_test_2)\n",
    "\n",
    "print(f'Train Accuracy: {score_train[1]*100}')\n",
    "print(f'Test Accuracy: {score_test[1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看舊模型的預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 157s 3ms/sample - loss: 1.7599 - categorical_accuracy: 0.4075\n",
      "10000/10000 [==============================] - 31s 3ms/sample - loss: 1.7696 - categorical_accuracy: 0.4080\n",
      "Train Accuracy: 40.75399935245514\n",
      "Test Accuracy: 40.79999923706055\n"
     ]
    }
   ],
   "source": [
    "score_train = model.evaluate(X_train, Y_train)\n",
    "score_test = model.evaluate(X_test, Y_test)\n",
    "\n",
    "print(f'Train Accuracy: {score_train[1]*100}')\n",
    "print(f'Test Accuracy: {score_test[1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
