{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as sf\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, Conv2D, GlobalAveragePooling2D, Activation,MaxPooling2D,MaxPool2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀入cifar10資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = datasets.cifar10.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "category= ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 檢視我們的測試資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 31.5, 31.5, -0.5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = np.random.randint(X_train.shape[0])\n",
    "X_sample = X_train[n]\n",
    "y_sample = Y_train[n].squeeze()\n",
    "\n",
    "plt.imshow(X_sample)\n",
    "plt.title(category[y_sample])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 標準化資料\n",
    "### 將資料轉成0到1之間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / X_train.max()\n",
    "X_test = X_test / X_test.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train, 10)\n",
    "Y_test = to_categorical(Y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看數據型態\n",
    "### 圖片為32X32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立分類cifar10的卷積神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_layers = [Conv2D(8, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu', name='Conv_1'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(32, (3, 3), padding='same', activation='relu', name='Conv_2'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(128, (3, 3), padding='same', activation='relu', name='Conv_3'),\n",
    "              GlobalAveragePooling2D()]\n",
    "\n",
    "FC_layers = [Dense(units=128, activation='relu'),\n",
    "             Dense(units=10, activation='softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 32, 32, 8)         224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 16, 16, 32)        2336      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 8, 8, 128)         36992     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 57,354\n",
      "Trainable params: 57,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(CNN_layers + FC_layers)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 組裝神經網路及訓練模型\n",
    "### 設定訓練數值:batch_size = 300 ,epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 37s 733us/sample - loss: 1.4781 - categorical_accuracy: 0.4607 - val_loss: 1.4513 - val_categorical_accuracy: 0.4698\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 37s 731us/sample - loss: 1.4597 - categorical_accuracy: 0.4676 - val_loss: 1.4611 - val_categorical_accuracy: 0.4628\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 36s 727us/sample - loss: 1.4561 - categorical_accuracy: 0.4688 - val_loss: 1.4367 - val_categorical_accuracy: 0.4720\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 36s 721us/sample - loss: 1.4371 - categorical_accuracy: 0.4784 - val_loss: 1.4093 - val_categorical_accuracy: 0.4845\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 37s 736us/sample - loss: 1.4233 - categorical_accuracy: 0.4834 - val_loss: 1.4277 - val_categorical_accuracy: 0.4770\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 37s 735us/sample - loss: 1.4113 - categorical_accuracy: 0.4874 - val_loss: 1.4079 - val_categorical_accuracy: 0.4789\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 36s 729us/sample - loss: 1.4027 - categorical_accuracy: 0.4905 - val_loss: 1.3986 - val_categorical_accuracy: 0.4879\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 36s 728us/sample - loss: 1.4003 - categorical_accuracy: 0.4913 - val_loss: 1.3876 - val_categorical_accuracy: 0.4903\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 36s 728us/sample - loss: 1.3816 - categorical_accuracy: 0.4981 - val_loss: 1.3775 - val_categorical_accuracy: 0.4958\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 37s 731us/sample - loss: 1.3777 - categorical_accuracy: 0.5009 - val_loss: 1.3555 - val_categorical_accuracy: 0.5068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x140ff47a780>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train, \n",
    "           batch_size=1000, \n",
    "           epochs=10,\n",
    "          validation_data=(X_test, Y_test)\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 存下模型、模型預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 18s 353us/sample - loss: 1.3584 - categorical_accuracy: 0.5087\n",
      "10000/10000 [==============================] - 4s 378us/sample - loss: 1.3555 - categorical_accuracy: 0.5068\n",
      "Train Accuracy: 50.86600184440613\n",
      "Test Accuracy: 50.679999589920044\n"
     ]
    }
   ],
   "source": [
    "score_train = model.evaluate(X_train, Y_train)\n",
    "score_test = model.evaluate(X_test, Y_test)\n",
    "print(f'Train Accuracy: {score_train[1]*100}')\n",
    "print(f'Test Accuracy: {score_test[1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('LeNet5_CIFAR10_HW.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 遷移學習 (Transfer Learning) 中的 Layer Transfer 的技巧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D \n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀入 Fasion mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_2, y_train_2), (X_test_2, y_test_2) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = X_train_2.reshape(60000, 28, 28, 1)/255\n",
    "X_test_2 = X_test_2.reshape(10000, 28, 28, 1)/255\n",
    "# One-hot encoding\n",
    "y_train_2 = to_categorical(y_train_2, 10)\n",
    "y_test_2 = to_categorical(y_test_2, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立Model2模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重新設定fashion_mnist CNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_layers_mnist = [Conv2D(8, (3, 3), input_shape=(28, 28, 1), padding='same', activation='relu', name='Conv_1'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(32, (3, 3), padding='same', activation='relu', name='Conv_2'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(128, (3, 3), padding='same', activation='relu', name='Conv_3'),\n",
    "              GlobalAveragePooling2D()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 應用Transfer Learning : 使用model的FC_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 28, 28, 8)         80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 14, 14, 32)        2336      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 7, 7, 128)         36992     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 57,210\n",
      "Trainable params: 57,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential(CNN_layers_mnist+FC_layers)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 40s 670us/sample - loss: 1.8390 - categorical_accuracy: 0.3353 - val_loss: 1.1779 - val_categorical_accuracy: 0.5996\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 38s 633us/sample - loss: 0.9887 - categorical_accuracy: 0.6478 - val_loss: 0.8812 - val_categorical_accuracy: 0.6815\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 38s 635us/sample - loss: 0.8122 - categorical_accuracy: 0.7101 - val_loss: 0.7958 - val_categorical_accuracy: 0.7193\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 38s 632us/sample - loss: 0.7395 - categorical_accuracy: 0.7329 - val_loss: 0.7446 - val_categorical_accuracy: 0.7326\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 38s 636us/sample - loss: 0.6980 - categorical_accuracy: 0.7450 - val_loss: 0.6929 - val_categorical_accuracy: 0.7520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1420f608c18>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer=Adam(),metrics=['categorical_accuracy'])\n",
    "model2.fit(X_train_2, y_train_2, batch_size=1000, epochs=5,validation_data=(X_test_2, y_test_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 存下模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save_weights('transferlearning_HW_mnist.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 17s 276us/sample - loss: 0.6682 - categorical_accuracy: 0.7578\n",
      "10000/10000 [==============================] - 3s 308us/sample - loss: 0.6929 - categorical_accuracy: 0.7520\n",
      "Train Accuracy: 75.78166723251343\n",
      "Test Accuracy: 75.19999742507935\n"
     ]
    }
   ],
   "source": [
    "model2.load_weights('transferlearning_HW_mnist.h5')\n",
    "\n",
    "score_train = model2.evaluate(X_train_2, y_train_2)\n",
    "score_test = model2.evaluate(X_test_2, y_test_2)\n",
    "\n",
    "print(f'Train Accuracy: {score_train[1]*100}')\n",
    "print(f'Test Accuracy: {score_test[1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看舊模型的預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 17s 333us/sample - loss: 3.5317 - categorical_accuracy: 0.3249\n",
      "10000/10000 [==============================] - 3s 338us/sample - loss: 3.5240 - categorical_accuracy: 0.3246\n",
      "Train Accuracy: 32.49000012874603\n",
      "Test Accuracy: 32.46000111103058\n"
     ]
    }
   ],
   "source": [
    "score_train = model.evaluate(X_train, Y_train)\n",
    "score_test = model.evaluate(X_test, Y_test)\n",
    "\n",
    "print(f'Train Accuracy: {score_train[1]*100}')\n",
    "print(f'Test Accuracy: {score_test[1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
