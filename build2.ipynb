{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator         #To increase the number of data\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width, image_height = 114,114 \n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, image_width, image_height)\n",
    "else:\n",
    "    input_shape = (image_width, image_height, 1)\n",
    "    \n",
    "train_dir = r'C:\\Users\\morri\\OneDrive\\桌面\\naruto-handsigns-predict-dl-master\\datasetTrain'                #input-to train\n",
    "validation_dir = r'C:\\Users\\morri\\OneDrive\\桌面\\naruto-handsigns-predict-dl-master\\datasetTest'            #input-to test\n",
    "save_dir=r'C:\\Users\\morri\\OneDrive\\桌面\\naruto-handsigns-predict-dl-master\\save'      #Data generated by ImageDataGenerator\n",
    "\n",
    "train_samples = 5830                        #input\n",
    "validation_samples = 5830                    #input\n",
    "\n",
    "batch_size = 12\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(9))                             #input\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8160 images belonging to 9 classes.\n",
      "Found 8160 images belonging to 9 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 485.8333333333333 steps, validate for 485.8333333333333 steps\n",
      "Epoch 1/25\n",
      "486/485 [==============================] - 89s 183ms/step - loss: 5.1217 - accuracy: 0.1787 - val_loss: 1.9906 - val_accuracy: 0.2934\n",
      "Epoch 2/25\n",
      "486/485 [==============================] - 85s 176ms/step - loss: 2.0144 - accuracy: 0.2462 - val_loss: 1.9000 - val_accuracy: 0.3364\n",
      "Epoch 3/25\n",
      "486/485 [==============================] - 88s 180ms/step - loss: 1.8624 - accuracy: 0.3025 - val_loss: 1.6783 - val_accuracy: 0.3529\n",
      "Epoch 4/25\n",
      "486/485 [==============================] - 89s 184ms/step - loss: 1.7345 - accuracy: 0.3510 - val_loss: 1.4925 - val_accuracy: 0.4624\n",
      "Epoch 5/25\n",
      "486/485 [==============================] - 89s 184ms/step - loss: 1.6419 - accuracy: 0.3957 - val_loss: 1.5983 - val_accuracy: 0.4604\n",
      "Epoch 6/25\n",
      "486/485 [==============================] - 87s 180ms/step - loss: 1.5857 - accuracy: 0.4184 - val_loss: 1.4605 - val_accuracy: 0.4621\n",
      "Epoch 7/25\n",
      "486/485 [==============================] - 87s 179ms/step - loss: 1.4966 - accuracy: 0.4551 - val_loss: 1.3859 - val_accuracy: 0.4962\n",
      "Epoch 8/25\n",
      "486/485 [==============================] - 90s 185ms/step - loss: 1.4616 - accuracy: 0.4616 - val_loss: 1.6852 - val_accuracy: 0.4726\n",
      "Epoch 9/25\n",
      "486/485 [==============================] - 93s 191ms/step - loss: 1.4120 - accuracy: 0.4839 - val_loss: 1.6636 - val_accuracy: 0.4525\n",
      "Epoch 10/25\n",
      "486/485 [==============================] - 92s 190ms/step - loss: 1.3708 - accuracy: 0.4973 - val_loss: 2.3229 - val_accuracy: 0.4511\n",
      "Epoch 11/25\n",
      "486/485 [==============================] - 89s 184ms/step - loss: 1.3231 - accuracy: 0.5194 - val_loss: 1.9463 - val_accuracy: 0.4081\n",
      "Epoch 12/25\n",
      "486/485 [==============================] - 86s 176ms/step - loss: 1.2775 - accuracy: 0.5410 - val_loss: 2.1162 - val_accuracy: 0.5303\n",
      "Epoch 13/25\n",
      "486/485 [==============================] - 88s 180ms/step - loss: 1.2374 - accuracy: 0.5528 - val_loss: 2.0977 - val_accuracy: 0.5324\n",
      "Epoch 14/25\n",
      "486/485 [==============================] - 89s 183ms/step - loss: 1.1994 - accuracy: 0.5636 - val_loss: 1.4440 - val_accuracy: 0.5362\n",
      "Epoch 15/25\n",
      "486/485 [==============================] - 89s 183ms/step - loss: 1.1628 - accuracy: 0.5782 - val_loss: 2.1950 - val_accuracy: 0.5238\n",
      "Epoch 16/25\n",
      "486/485 [==============================] - 88s 181ms/step - loss: 1.1099 - accuracy: 0.6046 - val_loss: 3.6083 - val_accuracy: 0.3801\n",
      "Epoch 17/25\n",
      "486/485 [==============================] - 84s 174ms/step - loss: 1.0897 - accuracy: 0.6039 - val_loss: 2.9360 - val_accuracy: 0.4736\n",
      "Epoch 18/25\n",
      "486/485 [==============================] - 88s 182ms/step - loss: 1.0460 - accuracy: 0.6229 - val_loss: 3.9632 - val_accuracy: 0.3825\n",
      "Epoch 19/25\n",
      "486/485 [==============================] - 87s 180ms/step - loss: 1.0255 - accuracy: 0.6252 - val_loss: 3.3479 - val_accuracy: 0.4729\n",
      "Epoch 20/25\n",
      "486/485 [==============================] - 85s 176ms/step - loss: 1.0204 - accuracy: 0.6392 - val_loss: 3.0051 - val_accuracy: 0.5485\n",
      "Epoch 21/25\n",
      "486/485 [==============================] - 87s 179ms/step - loss: 1.0067 - accuracy: 0.6392 - val_loss: 2.0344 - val_accuracy: 0.5710\n",
      "Epoch 22/25\n",
      "486/485 [==============================] - 89s 184ms/step - loss: 0.9561 - accuracy: 0.6529 - val_loss: 3.8120 - val_accuracy: 0.5331\n",
      "Epoch 23/25\n",
      "486/485 [==============================] - 93s 191ms/step - loss: 0.9276 - accuracy: 0.6617 - val_loss: 3.2544 - val_accuracy: 0.4961\n",
      "Epoch 24/25\n",
      "486/485 [==============================] - 96s 197ms/step - loss: 0.9445 - accuracy: 0.6603 - val_loss: 3.3121 - val_accuracy: 0.5576\n",
      "Epoch 25/25\n",
      "486/485 [==============================] - 90s 186ms/step - loss: 0.9220 - accuracy: 0.6634 - val_loss: 2.6219 - val_accuracy: 0.5971\n"
     ]
    }
   ],
   "source": [
    "###利用ImageDataGenerator生成一個數據生成器,word中有解釋\n",
    "###使用的參數有zoom_range, horizontal_flip,vertical_flip,rotation_range,shear_range和 width_shift_range & height_shift_range,詳細的介紹在word\n",
    "train_datagen = ImageDataGenerator(zoom_range=0.0, horizontal_flip=True,vertical_flip=True,rotation_range=30,shear_range=0.5,width_shift_range=0.5,height_shift_range=0.5)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(image_width, image_height), batch_size=batch_size, \n",
    "                                                    color_mode=\"grayscale\", class_mode='categorical',save_to_dir=save_dir)\n",
    "test_datagen = ImageDataGenerator()\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir, target_size=(image_width, image_height), batch_size=batch_size, \n",
    "                                                        color_mode=\"grayscale\", class_mode='categorical',save_to_dir=save_dir)\n",
    "\n",
    "\n",
    "model.fit_generator(train_generator, steps_per_epoch= train_samples / batch_size, epochs=epochs, validation_data=validation_generator, \n",
    "                    validation_steps= validation_samples / batch_size)\n",
    "\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model_in_json.json\", \"w\") as json_file:\n",
    "    json.dump(model_json, json_file)\n",
    "\n",
    "\n",
    "model.save_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
