{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout,BatchNormalization\n",
    "from tensorflow.keras.layers import Input, concatenate\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras.metrics as metric\n",
    "import os\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定義變數數集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_CLASS=9\n",
    "LEARNING_RATE=0.01\n",
    "MOMENTUM=0.9\n",
    "DROPOUT=0.4\n",
    "WEIGHT_DECAY=0.0005\n",
    "LRN2D_NORM=True\n",
    "DATA_FORMAT='channels_last' # Theano:'channels_first' Tensorflow:'channels_last'\n",
    "USE_BN=True\n",
    "IM_WIDTH=64\n",
    "IM_HEIGHT=64\n",
    "batch_size=400\n",
    "EPOCH= 5\n",
    "\n",
    "train_root= r'C:\\Users\\morri\\OneDrive\\桌面\\naruto-handsigns-predict-dl-master\\datasetTrain'\n",
    "vaildation_root= r'C:\\Users\\morri\\OneDrive\\桌面\\naruto-handsigns-predict-dl-master\\datasetvaildation'\n",
    "test_root= r'C:\\Users\\morri\\OneDrive\\桌面\\naruto-handsigns-predict-dl-master\\datasetTest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練生成器 測試生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6223 images belonging to 9 classes.\n",
      "Found 814 images belonging to 9 classes.\n",
      "Found 780 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "#train data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    featurewise_center=True\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "  train_root,\n",
    "  target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "  batch_size=batch_size,\n",
    ")\n",
    "\n",
    "#vaild data\n",
    "vaild_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    featurewise_center=True\n",
    ")\n",
    "vaild_generator = train_datagen.flow_from_directory(\n",
    "  vaildation_root,\n",
    "  target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "  batch_size=batch_size,\n",
    ")\n",
    "\n",
    "#test data\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    featurewise_center=True\n",
    ")\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "  test_root,\n",
    "  target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "  batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定義函數學習機"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization\n",
    "def conv2D_lrn2d(x,filters,kernel_size,strides=(1,1),padding='same',data_format=DATA_FORMAT,dilation_rate=(1,1),activation='relu',use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,lrn2d_norm=LRN2D_NORM,weight_decay=WEIGHT_DECAY):\n",
    "    #l2 normalization\n",
    "    if weight_decay:\n",
    "        kernel_regularizer=regularizers.l2(weight_decay)\n",
    "        bias_regularizer=regularizers.l2(weight_decay)\n",
    "    else:\n",
    "        kernel_regularizer=None\n",
    "        bias_regularizer=None\n",
    "\n",
    "    x=Conv2D(filters=filters,kernel_size=kernel_size,strides=strides,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(x)\n",
    "\n",
    "    if lrn2d_norm:\n",
    "        #batch normalization\n",
    "        x=BatchNormalization()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def inception_module(x,params,concat_axis,padding='same',data_format=DATA_FORMAT,dilation_rate=(1,1),activation='relu',use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,lrn2d_norm=LRN2D_NORM,weight_decay=None):\n",
    "    (branch1,branch2,branch3,branch4)=params\n",
    "    if weight_decay:\n",
    "        kernel_regularizer=regularizers.l2(weight_decay)\n",
    "        bias_regularizer=regularizers.l2(weight_decay)\n",
    "    else:\n",
    "        kernel_regularizer=None\n",
    "        bias_regularizer=None\n",
    "    #1x1\n",
    "    pathway1=Conv2D(filters=branch1[0],kernel_size=(1,1),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(x)\n",
    "\n",
    "    #1x1->3x3\n",
    "    pathway2=Conv2D(filters=branch2[0],kernel_size=(1,1),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(x)\n",
    "    pathway2=Conv2D(filters=branch2[1],kernel_size=(3,3),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(pathway2)\n",
    "\n",
    "    #1x1->5x5\n",
    "    pathway3=Conv2D(filters=branch3[0],kernel_size=(1,1),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(x)\n",
    "    pathway3=Conv2D(filters=branch3[1],kernel_size=(5,5),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(pathway3)\n",
    "\n",
    "    #3x3->1x1\n",
    "    pathway4=MaxPooling2D(pool_size=(3,3),strides=1,padding=padding,data_format=DATA_FORMAT)(x)\n",
    "    pathway4=Conv2D(filters=branch4[0],kernel_size=(1,1),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(pathway4)\n",
    "\n",
    "    return concatenate([pathway1,pathway2,pathway3,pathway4],axis=concat_axis)\n",
    "\n",
    "def create_model():\n",
    "    #Data format:tensorflow,channels_last;theano,channels_last\n",
    "    if DATA_FORMAT=='channels_first':\n",
    "        INP_SHAPE=(3,64,64)\n",
    "        img_input=Input(shape=INP_SHAPE)\n",
    "        CONCAT_AXIS=1\n",
    "    elif DATA_FORMAT=='channels_last':\n",
    "        INP_SHAPE=(64,64,3)\n",
    "        img_input=Input(shape=INP_SHAPE)\n",
    "        CONCAT_AXIS=3\n",
    "    else:\n",
    "        raise Exception('Invalid Dim Ordering')\n",
    "\n",
    "    x=conv2D_lrn2d(img_input,64,(5,5),2,padding='same',lrn2d_norm=False)\n",
    "    x=MaxPooling2D(pool_size=(3,3),strides=2,padding='same',data_format=DATA_FORMAT)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "\n",
    "    x=conv2D_lrn2d(x,64,(1,1),1,padding='same',lrn2d_norm=False)\n",
    "\n",
    "    x=conv2D_lrn2d(x,192,(3,3),1,padding='same',lrn2d_norm=True)\n",
    "    x=MaxPooling2D(pool_size=(3,3),strides=2,padding='same',data_format=DATA_FORMAT)(x)\n",
    "\n",
    "    x=inception_module(x,params=[(64,),(96,128),(16,32),(32,)],concat_axis=CONCAT_AXIS) #3a\n",
    "    x=inception_module(x,params=[(128,),(128,192),(32,96),(64,)],concat_axis=CONCAT_AXIS) #3b\n",
    "    x=MaxPooling2D(pool_size=(3,3),strides=2,padding='same',data_format=DATA_FORMAT)(x)\n",
    "\n",
    "    \n",
    "    ### 為了讓訓練的速度增加 將兩層數收起來\n",
    "    \n",
    "    #x=inception_module(x,params=[(192,),(96,208),(16,48),(64,)],concat_axis=CONCAT_AXIS) #4a\n",
    "    #x=inception_module(x,params=[(160,),(112,224),(24,64),(64,)],concat_axis=CONCAT_AXIS) #4b\n",
    "    #x=inception_module(x,params=[(128,),(128,256),(24,64),(64,)],concat_axis=CONCAT_AXIS) #4c\n",
    "    #x=inception_module(x,params=[(112,),(144,288),(32,64),(64,)],concat_axis=CONCAT_AXIS) #4d\n",
    "    #x=inception_module(x,params=[(256,),(160,320),(32,128),(128,)],concat_axis=CONCAT_AXIS) #4e\n",
    "    #x=MaxPooling2D(pool_size=(3,3),strides=2,padding='same',data_format=DATA_FORMAT)(x)\n",
    "\n",
    "    #x=inception_module(x,params=[(256,),(160,320),(32,128),(128,)],concat_axis=CONCAT_AXIS) #5a\n",
    "    #x=inception_module(x,params=[(384,),(192,384),(48,128),(128,)],concat_axis=CONCAT_AXIS) #5b\n",
    "    #x=AveragePooling2D(pool_size=(7,7),strides=1,padding='valid',data_format=DATA_FORMAT)(x)\n",
    "\n",
    "    x=Flatten()(x)\n",
    "    x=Dropout(DROPOUT)(x)\n",
    "    x=Dense(NB_CLASS,activation='linear')(x)\n",
    "    x=Dense(NB_CLASS,activation='softmax')(x)\n",
    "\n",
    "    return x,img_input,CONCAT_AXIS,INP_SHAPE,DATA_FORMAT\n",
    "\n",
    "\n",
    "def check_print():\n",
    "    # Create the Model\n",
    "    x,img_input,CONCAT_AXIS,INP_SHAPE,DATA_FORMAT=create_model()\n",
    "\n",
    "    # Create a Keras Model\n",
    "    model=Model(inputs=img_input,outputs=[x])\n",
    "    model.summary()\n",
    "\n",
    "    # Save a PNG of the Model Build\n",
    "    # plot_model(model,to_file='GoogLeNet.png',show_shapes=True)\n",
    "\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc',metric.top_k_categorical_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 64)   4864        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 16, 16, 64)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 16, 16, 64)   256         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 16, 16, 64)   4160        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 192)  110784      conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16, 16, 192)  768         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 192)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 8, 8, 96)     18528       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 8, 8, 16)     3088        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 192)    0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 64)     12352       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 8, 8, 128)    110720      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 8, 32)     12832       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 8, 8, 32)     6176        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 256)    0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 128)    32896       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 32)     8224        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 256)    0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 128)    32896       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 192)    221376      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 96)     76896       conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 64)     16448       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 480)    0           conv2d_9[0][0]                   \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 480)    0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 7680)         0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 7680)         0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 9)            69129       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 9)            90          dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 742,483\n",
      "Trainable params: 741,971\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morri\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 15.5575 steps, validate for 2.035 steps\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morri\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/15 [==============================] - 111s 7s/step - loss: 3.2580 - acc: 0.2505 - top_k_categorical_accuracy: 0.7619 - val_loss: 5.1258 - val_acc: 0.1388 - val_top_k_categorical_accuracy: 0.7211\n",
      "Epoch 2/5\n",
      "16/15 [==============================] - 83s 5s/step - loss: 1.2227 - acc: 0.5912 - top_k_categorical_accuracy: 0.9664 - val_loss: 16.3697 - val_acc: 0.2260 - val_top_k_categorical_accuracy: 0.7273\n",
      "Epoch 3/5\n",
      "16/15 [==============================] - 80s 5s/step - loss: 0.5990 - acc: 0.8300 - top_k_categorical_accuracy: 0.9960 - val_loss: 24.0351 - val_acc: 0.2383 - val_top_k_categorical_accuracy: 0.7346\n",
      "Epoch 4/5\n",
      "16/15 [==============================] - 83s 5s/step - loss: 0.2601 - acc: 0.9466 - top_k_categorical_accuracy: 0.9987 - val_loss: 17.6152 - val_acc: 0.3157 - val_top_k_categorical_accuracy: 0.6302\n",
      "Epoch 5/5\n",
      "16/15 [==============================] - 85s 5s/step - loss: 0.1508 - acc: 0.9791 - top_k_categorical_accuracy: 0.9998 - val_loss: 14.7042 - val_acc: 0.1953 - val_top_k_categorical_accuracy: 0.7187\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    if os.path.exists('inception_1.h5'):\n",
    "        model=load_model('inception_1.h5')\n",
    "    else:\n",
    "        model=check_print()\n",
    "\n",
    "    history = model.fit_generator(train_generator,validation_data=vaild_generator,epochs=EPOCH,steps_per_epoch=train_generator.n/batch_size\n",
    "                        ,validation_steps=vaild_generator.n/batch_size)\n",
    "    model.save('inception_1.h5')\n",
    "   ## model.metrics=['acc',metric.top_k_categorical_accuracy]\n",
    "    ## loss,acc,top_acc=model.evaluate_generator(test_generator,steps=test_generator.n/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model_json = model.to_json()\n",
    "with open(\"model_in_json.json\", \"w\") as json_file:\n",
    "    json.dump(model_json, json_file)\n",
    "\n",
    "model.save_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-6cd55a032ae6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFrameImage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mFrameImage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFrameImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFrameImage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFrameImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mCLIP_X1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCLIP_Y1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mCLIP_X2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCLIP_Y2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "import cv2\n",
    "import sys, os\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import json\n",
    "from PIL import Image\n",
    "import pygame\n",
    "\n",
    "pygame.init()\n",
    "screen = pygame.display.set_mode((900,900),pygame.RESIZABLE)\n",
    "\n",
    "CLIP_X1 = 160\n",
    "CLIP_Y1 = 140\n",
    "CLIP_X2 = 400\n",
    "CLIP_Y2 = 360\n",
    "\n",
    "with open('model_in_json.json','r') as f:\n",
    "    model_json = json.load(f)\n",
    "loaded_model = model_from_json(model_json)\n",
    "loaded_model.load_weights('model_weights.h5')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _, FrameImage = cap.read()\n",
    "    FrameImage = cv2.flip(FrameImage, 1)\n",
    "    cv2.imshow(\"\", FrameImage)\n",
    "    cv2.rectangle(FrameImage, (CLIP_X1, CLIP_Y1), (CLIP_X2, CLIP_Y2), (0,255,0) ,1)\n",
    "\n",
    "    ROI = FrameImage[CLIP_Y1:CLIP_Y2, CLIP_X1:CLIP_X2]\n",
    "    ROI = cv2.resize(ROI, (64, 64)) \n",
    "    ROI = cv2.cvtColor(ROI, cv2.COLOR_BGR2GRAY)\n",
    "    #ROI= cv2.add(ROI,np.array([40.0]))\n",
    "    _, output = cv2.threshold(ROI, 100, 255, cv2.THRESH_BINARY) # adjust brightness\n",
    "    \n",
    "    SHOWROI = cv2.resize(ROI, (256, 256)) \n",
    "    _, output2 = cv2.threshold(SHOWROI, 100, 255, cv2.THRESH_BINARY)\n",
    "    cv2.imshow(\"ROI\", output2)\n",
    "    \n",
    "    result = loaded_model.predict(output.reshape(1, 64, 64, 1))\n",
    "    predict =   { 'bird':    result[0][0],\n",
    "                  'dragon':    result[0][1],    \n",
    "                  'horse':    result[0][2],\n",
    "                  'monkey':    result[0][3],\n",
    "                  'dog':    result[0][3],\n",
    "                  'ox':    result[0][5],\n",
    "                  'serpent':    result[0][6],\n",
    "                  'ram':    result[0][7],\n",
    "                  }\n",
    "    \n",
    "    predict = sorted(predict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    if(predict[0][1] == 1.0):\n",
    "        predict_img  = pygame.image.load(os.getcwd() + '/dataset/images/' + predict[0][0] + '.png')\n",
    "    else:\n",
    "        predict_img  = pygame.image.load(os.getcwd() + '/dataset/images/nosign.png')\n",
    "    predict_img = pygame.transform.scale(predict_img, (900, 900))\n",
    "    screen.blit(predict_img, (0,0))\n",
    "    pygame.display.flip()\n",
    "    interrupt = cv2.waitKey(10)\n",
    "\n",
    "    if interrupt & 0xFF == ord('q'): # esc key\n",
    "        break\n",
    "            \n",
    "pygame.quit()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
