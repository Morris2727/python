{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout,BatchNormalization\n",
    "from tensorflow.keras.layers import Input, concatenate\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras.metrics as metric\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8160 images belonging to 9 classes.\n",
      "Found 8160 images belonging to 9 classes.\n",
      "Found 8160 images belonging to 9 classes.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 114, 114, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 57, 57, 64)   4864        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 29, 29, 64)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 29, 29, 64)   256         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 29, 29, 64)   4160        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 29, 29, 192)  110784      conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 29, 29, 192)  768         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 15, 15, 192)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 15, 15, 96)   18528       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 15, 15, 16)   3088        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 15, 15, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 15, 15, 64)   12352       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 15, 15, 128)  110720      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 15, 15, 32)   12832       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 15, 15, 32)   6176        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 15, 15, 256)  0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 15, 15, 128)  32896       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 15, 15, 32)   8224        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 15, 15, 256)  0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 15, 15, 128)  32896       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 15, 15, 192)  221376      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 15, 15, 96)   76896       conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 15, 15, 64)   16448       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 15, 15, 480)  0           conv2d_9[0][0]                   \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 480)    0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 30720)        0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 30720)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 9)            276489      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 9)            90          dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 949,843\n",
      "Trainable params: 949,331\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-3-6d5529aa11ea>:177: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morri\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 20.4 steps, validate for 20.4 steps\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morri\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/20 [==============================] - 414s 20s/step - loss: 4.0988 - acc: 0.2574 - top_k_categorical_accuracy: 0.7447 - val_loss: 5.2950 - val_acc: 0.0710 - val_top_k_categorical_accuracy: 0.6424\n",
      "Epoch 2/25\n",
      "21/20 [==============================] - 167s 8s/step - loss: 1.1127 - acc: 0.6550 - top_k_categorical_accuracy: 0.9620 - val_loss: 14.1526 - val_acc: 0.1472 - val_top_k_categorical_accuracy: 0.6189\n",
      "Epoch 3/25\n",
      "21/20 [==============================] - 157s 7s/step - loss: 0.4313 - acc: 0.8938 - top_k_categorical_accuracy: 0.9982 - val_loss: 16.0016 - val_acc: 0.2191 - val_top_k_categorical_accuracy: 0.7496\n",
      "Epoch 4/25\n",
      "21/20 [==============================] - 167s 8s/step - loss: 0.2229 - acc: 0.9582 - top_k_categorical_accuracy: 0.9994 - val_loss: 11.0054 - val_acc: 0.1662 - val_top_k_categorical_accuracy: 0.7360\n",
      "Epoch 5/25\n",
      "21/20 [==============================] - 163s 8s/step - loss: 0.1738 - acc: 0.9718 - top_k_categorical_accuracy: 0.9996 - val_loss: 8.5508 - val_acc: 0.2309 - val_top_k_categorical_accuracy: 0.8103\n",
      "Epoch 6/25\n",
      "21/20 [==============================] - 158s 8s/step - loss: 0.1393 - acc: 0.9841 - top_k_categorical_accuracy: 1.0000 - val_loss: 7.0655 - val_acc: 0.2511 - val_top_k_categorical_accuracy: 0.9124\n",
      "Epoch 7/25\n",
      "21/20 [==============================] - 162s 8s/step - loss: 0.1126 - acc: 0.9917 - top_k_categorical_accuracy: 1.0000 - val_loss: 6.2624 - val_acc: 0.2282 - val_top_k_categorical_accuracy: 0.9551\n",
      "Epoch 8/25\n",
      "21/20 [==============================] - 177s 8s/step - loss: 0.1040 - acc: 0.9937 - top_k_categorical_accuracy: 0.9999 - val_loss: 2.6163 - val_acc: 0.3902 - val_top_k_categorical_accuracy: 0.9920\n",
      "Epoch 9/25\n",
      "21/20 [==============================] - 156s 7s/step - loss: 0.1034 - acc: 0.9944 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.1476 - val_acc: 0.4407 - val_top_k_categorical_accuracy: 0.9953\n",
      "Epoch 10/25\n",
      "21/20 [==============================] - 159s 8s/step - loss: 0.1001 - acc: 0.9936 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.8650 - val_acc: 0.3592 - val_top_k_categorical_accuracy: 0.9968\n",
      "Epoch 11/25\n",
      "21/20 [==============================] - 162s 8s/step - loss: 0.0955 - acc: 0.9961 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.4387 - val_acc: 0.6212 - val_top_k_categorical_accuracy: 0.9950\n",
      "Epoch 12/25\n",
      "21/20 [==============================] - 162s 8s/step - loss: 0.0890 - acc: 0.9974 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4994 - val_acc: 0.8626 - val_top_k_categorical_accuracy: 0.9963\n",
      "Epoch 13/25\n",
      "21/20 [==============================] - 177s 8s/step - loss: 0.0857 - acc: 0.9978 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1715 - val_acc: 0.9735 - val_top_k_categorical_accuracy: 0.9996\n",
      "Epoch 14/25\n",
      "21/20 [==============================] - 172s 8s/step - loss: 0.0858 - acc: 0.9979 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1179 - val_acc: 0.9911 - val_top_k_categorical_accuracy: 0.9999\n",
      "Epoch 15/25\n",
      "21/20 [==============================] - 151s 7s/step - loss: 0.0869 - acc: 0.9967 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.7114 - val_acc: 0.8083 - val_top_k_categorical_accuracy: 0.9923\n",
      "Epoch 16/25\n",
      "21/20 [==============================] - 160s 8s/step - loss: 0.0833 - acc: 0.9975 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.7609 - val_acc: 0.7612 - val_top_k_categorical_accuracy: 0.9994\n",
      "Epoch 17/25\n",
      "21/20 [==============================] - 187s 9s/step - loss: 0.0794 - acc: 0.9983 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.3787 - val_acc: 0.8815 - val_top_k_categorical_accuracy: 0.9999\n",
      "Epoch 18/25\n",
      "21/20 [==============================] - 163s 8s/step - loss: 0.0844 - acc: 0.9960 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1730 - val_acc: 0.9680 - val_top_k_categorical_accuracy: 0.9993\n",
      "Epoch 19/25\n",
      "21/20 [==============================] - 164s 8s/step - loss: 0.0846 - acc: 0.9952 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0861 - val_acc: 0.9973 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 20/25\n",
      "21/20 [==============================] - 166s 8s/step - loss: 0.0752 - acc: 0.9984 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0853 - val_acc: 0.9972 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 21/25\n",
      "21/20 [==============================] - 163s 8s/step - loss: 0.0771 - acc: 0.9979 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0785 - val_acc: 0.9984 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 22/25\n",
      "21/20 [==============================] - 163s 8s/step - loss: 0.0729 - acc: 0.9993 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0827 - val_acc: 0.9964 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 23/25\n",
      "21/20 [==============================] - 163s 8s/step - loss: 0.0717 - acc: 0.9987 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0747 - val_acc: 0.9983 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 24/25\n",
      "21/20 [==============================] - 164s 8s/step - loss: 0.0701 - acc: 0.9985 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0714 - val_acc: 0.9995 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 25/25\n",
      "21/20 [==============================] - 162s 8s/step - loss: 0.0683 - acc: 0.9994 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0682 - val_acc: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't set the attribute \"metrics\", likely because it conflicts with an existing read-only @property of the object. Please choose a different name.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   2238\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2239\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutoTrackable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2240\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: can't set attribute",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-6d5529aa11ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    177\u001b[0m                         ,validation_steps=vaild_generator.n/batch_size)\n\u001b[0;32m    178\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'inception_1.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtop_k_categorical_accuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop_acc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m    439\u001b[0m                          ' Always start with this line.'), None)\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m     \u001b[1;31m# Keep track of metric instance created in subclassed model/layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   2242\u001b[0m             ('Can\\'t set the attribute \"{}\", likely because it conflicts with '\n\u001b[0;32m   2243\u001b[0m              \u001b[1;34m'an existing read-only @property of the object. Please choose a '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2244\u001b[1;33m              'different name.').format(name))\n\u001b[0m\u001b[0;32m   2245\u001b[0m       \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't set the attribute \"metrics\", likely because it conflicts with an existing read-only @property of the object. Please choose a different name."
     ]
    }
   ],
   "source": [
    "NB_CLASS=9\n",
    "LEARNING_RATE=0.01\n",
    "MOMENTUM=0.9\n",
    "DROPOUT=0.4\n",
    "WEIGHT_DECAY=0.0005\n",
    "LRN2D_NORM=True\n",
    "DATA_FORMAT='channels_last' # Theano:'channels_first' Tensorflow:'channels_last'\n",
    "USE_BN=True\n",
    "\n",
    "train_root= r'C:\\Users\\morri\\OneDrive\\桌面\\naruto-handsigns-predict-dl-master\\datasetTrain'\n",
    "vaildation_root= r'C:\\Users\\morri\\OneDrive\\桌面\\naruto-handsigns-predict-dl-master\\datasetTrain'\n",
    "test_root= r'C:\\Users\\morri\\OneDrive\\桌面\\naruto-handsigns-predict-dl-master\\datasetTest'\n",
    "\n",
    "IM_WIDTH=114\n",
    "IM_HEIGHT=114\n",
    "batch_size=400\n",
    "EPOCH= 25\n",
    "\n",
    "#train data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    featurewise_center=True\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "  train_root,\n",
    "  target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "  batch_size=batch_size,\n",
    ")\n",
    "\n",
    "#vaild data\n",
    "vaild_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    featurewise_center=True\n",
    ")\n",
    "vaild_generator = train_datagen.flow_from_directory(\n",
    "  vaildation_root,\n",
    "  target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "  batch_size=batch_size,\n",
    ")\n",
    "\n",
    "#test data\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    featurewise_center=True\n",
    ")\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "  test_root,\n",
    "  target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "  batch_size=batch_size,\n",
    ")\n",
    "\n",
    "#normalization\n",
    "def conv2D_lrn2d(x,filters,kernel_size,strides=(1,1),padding='same',data_format=DATA_FORMAT,dilation_rate=(1,1),activation='relu',use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,lrn2d_norm=LRN2D_NORM,weight_decay=WEIGHT_DECAY):\n",
    "    #l2 normalization\n",
    "    if weight_decay:\n",
    "        kernel_regularizer=regularizers.l2(weight_decay)\n",
    "        bias_regularizer=regularizers.l2(weight_decay)\n",
    "    else:\n",
    "        kernel_regularizer=None\n",
    "        bias_regularizer=None\n",
    "\n",
    "    x=Conv2D(filters=filters,kernel_size=kernel_size,strides=strides,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(x)\n",
    "\n",
    "    if lrn2d_norm:\n",
    "        #batch normalization\n",
    "        x=BatchNormalization()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def inception_module(x,params,concat_axis,padding='same',data_format=DATA_FORMAT,dilation_rate=(1,1),activation='relu',use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,lrn2d_norm=LRN2D_NORM,weight_decay=None):\n",
    "    (branch1,branch2,branch3,branch4)=params\n",
    "    if weight_decay:\n",
    "        kernel_regularizer=regularizers.l2(weight_decay)\n",
    "        bias_regularizer=regularizers.l2(weight_decay)\n",
    "    else:\n",
    "        kernel_regularizer=None\n",
    "        bias_regularizer=None\n",
    "    #1x1\n",
    "    pathway1=Conv2D(filters=branch1[0],kernel_size=(1,1),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(x)\n",
    "\n",
    "    #1x1->3x3\n",
    "    pathway2=Conv2D(filters=branch2[0],kernel_size=(1,1),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(x)\n",
    "    pathway2=Conv2D(filters=branch2[1],kernel_size=(3,3),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(pathway2)\n",
    "\n",
    "    #1x1->5x5\n",
    "    pathway3=Conv2D(filters=branch3[0],kernel_size=(1,1),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(x)\n",
    "    pathway3=Conv2D(filters=branch3[1],kernel_size=(5,5),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(pathway3)\n",
    "\n",
    "    #3x3->1x1\n",
    "    pathway4=MaxPooling2D(pool_size=(3,3),strides=1,padding=padding,data_format=DATA_FORMAT)(x)\n",
    "    pathway4=Conv2D(filters=branch4[0],kernel_size=(1,1),strides=1,padding=padding,data_format=data_format,dilation_rate=dilation_rate,activation=activation,use_bias=use_bias,kernel_initializer=kernel_initializer,bias_initializer=bias_initializer,kernel_regularizer=kernel_regularizer,bias_regularizer=bias_regularizer,activity_regularizer=activity_regularizer,kernel_constraint=kernel_constraint,bias_constraint=bias_constraint)(pathway4)\n",
    "\n",
    "    return concatenate([pathway1,pathway2,pathway3,pathway4],axis=concat_axis)\n",
    "\n",
    "def create_model():\n",
    "    #Data format:tensorflow,channels_last;theano,channels_last\n",
    "    if DATA_FORMAT=='channels_first':\n",
    "        INP_SHAPE=(3,114,114)\n",
    "        img_input=Input(shape=INP_SHAPE)\n",
    "        CONCAT_AXIS=1\n",
    "    elif DATA_FORMAT=='channels_last':\n",
    "        INP_SHAPE=(114,114,3)\n",
    "        img_input=Input(shape=INP_SHAPE)\n",
    "        CONCAT_AXIS=3\n",
    "    else:\n",
    "        raise Exception('Invalid Dim Ordering')\n",
    "\n",
    "    x=conv2D_lrn2d(img_input,64,(5,5),2,padding='same',lrn2d_norm=False)\n",
    "    x=MaxPooling2D(pool_size=(3,3),strides=2,padding='same',data_format=DATA_FORMAT)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "\n",
    "    x=conv2D_lrn2d(x,64,(1,1),1,padding='same',lrn2d_norm=False)\n",
    "\n",
    "    x=conv2D_lrn2d(x,192,(3,3),1,padding='same',lrn2d_norm=True)\n",
    "    x=MaxPooling2D(pool_size=(3,3),strides=2,padding='same',data_format=DATA_FORMAT)(x)\n",
    "\n",
    "    x=inception_module(x,params=[(64,),(96,128),(16,32),(32,)],concat_axis=CONCAT_AXIS) #3a\n",
    "    x=inception_module(x,params=[(128,),(128,192),(32,96),(64,)],concat_axis=CONCAT_AXIS) #3b\n",
    "    x=MaxPooling2D(pool_size=(3,3),strides=2,padding='same',data_format=DATA_FORMAT)(x)\n",
    "\n",
    "    \n",
    "    ### 為了讓訓練的速度增加 將兩層數收起來\n",
    "    \n",
    "    #x=inception_module(x,params=[(192,),(96,208),(16,48),(64,)],concat_axis=CONCAT_AXIS) #4a\n",
    "    #x=inception_module(x,params=[(160,),(112,224),(24,64),(64,)],concat_axis=CONCAT_AXIS) #4b\n",
    "    #x=inception_module(x,params=[(128,),(128,256),(24,64),(64,)],concat_axis=CONCAT_AXIS) #4c\n",
    "    #x=inception_module(x,params=[(112,),(144,288),(32,64),(64,)],concat_axis=CONCAT_AXIS) #4d\n",
    "    #x=inception_module(x,params=[(256,),(160,320),(32,128),(128,)],concat_axis=CONCAT_AXIS) #4e\n",
    "    #x=MaxPooling2D(pool_size=(3,3),strides=2,padding='same',data_format=DATA_FORMAT)(x)\n",
    "\n",
    "    #x=inception_module(x,params=[(256,),(160,320),(32,128),(128,)],concat_axis=CONCAT_AXIS) #5a\n",
    "    #x=inception_module(x,params=[(384,),(192,384),(48,128),(128,)],concat_axis=CONCAT_AXIS) #5b\n",
    "    #x=AveragePooling2D(pool_size=(7,7),strides=1,padding='valid',data_format=DATA_FORMAT)(x)\n",
    "\n",
    "    x=Flatten()(x)\n",
    "    x=Dropout(DROPOUT)(x)\n",
    "    x=Dense(NB_CLASS,activation='linear')(x)\n",
    "    x=Dense(NB_CLASS,activation='softmax')(x)\n",
    "\n",
    "    return x,img_input,CONCAT_AXIS,INP_SHAPE,DATA_FORMAT\n",
    "\n",
    "\n",
    "def check_print():\n",
    "    # Create the Model\n",
    "    x,img_input,CONCAT_AXIS,INP_SHAPE,DATA_FORMAT=create_model()\n",
    "\n",
    "    # Create a Keras Model\n",
    "    model=Model(inputs=img_input,outputs=[x])\n",
    "    model.summary()\n",
    "\n",
    "    # Save a PNG of the Model Build\n",
    "    # plot_model(model,to_file='GoogLeNet.png',show_shapes=True)\n",
    "\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc',metric.top_k_categorical_accuracy])\n",
    "    return model\n",
    "\n",
    "if __name__=='__main__':\n",
    "    if os.path.exists('inception_1.h5'):\n",
    "        model=load_model('inception_1.h5')\n",
    "    else:\n",
    "        model=check_print()\n",
    "\n",
    "    model.fit_generator(train_generator,validation_data=vaild_generator,epochs=EPOCH,steps_per_epoch=train_generator.n/batch_size\n",
    "                        ,validation_steps=vaild_generator.n/batch_size)\n",
    "    model.save('inception_1.h5')\n",
    "    model.metrics=['acc',metric.top_k_categorical_accuracy]\n",
    "    loss,acc,top_acc=model.evaluate_generator(test_generator,steps=test_generator.n/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
